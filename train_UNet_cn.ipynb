{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shlee\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import os\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "import copy\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('./train_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Tuple\n",
    "import PIL\n",
    "PIL.Image.ANTIALIAS = PIL.Image.LANCZOS\n",
    "from PIL import Image\n",
    "num_classes = 21\n",
    "batch_size = 4\n",
    "num_epoch = 100\n",
    "class VOCSegDataset(VOCSegmentation):\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        image = Image.open(self.images[index]).convert('RGB')\n",
    "        label = Image.open(self.targets[index])\n",
    "        image = self.transform(image)\n",
    "        label = self.target_transform(label)\n",
    "        label = (label*255)\n",
    "        return image , label.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image_transforms = transforms.Compose([\n",
    "                                    transforms.Resize((256,256)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5) ),\n",
    "                                     ])\n",
    "target_transform = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     ])\n",
    "train_dataset = VOCSegDataset('./data',\n",
    "                             year='2012',download=False ,image_set='train', transform=image_transforms, target_transform=target_transform)\n",
    "val_dataset = VOCSegDataset('./data',\n",
    "                           year='2012',download=False, image_set='trainval', transform=image_transforms, target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=False,num_workers=0)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_size,shuffle=False,num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UNet import UNet\n",
    "device = torch.device(\"cuda\")\n",
    "model = UNet(3,21) # pascalVOC has 21 classes including background\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "import torch.optim \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n"
     ]
    }
   ],
   "source": [
    "# 배치 수 확인\n",
    "total_batch = len(train_loader)\n",
    "print(total_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "celoss = nn.CrossEntropyLoss(ignore_index=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sementic_image(img): # img is 256 256 tensor\n",
    "    colors = [\n",
    "    [128, 128, 128],    \n",
    "    [0, 0, 255],   \n",
    "    [0, 255, 0],   \n",
    "    [255, 0, 0],   \n",
    "    [255, 255, 0], \n",
    "    [0, 255, 255], \n",
    "    [255, 0, 255], \n",
    "    [192, 192, 192], \n",
    "    [128, 128, 128], \n",
    "    [128, 0, 0],   \n",
    "    [128, 128, 0], \n",
    "    [0, 128, 0],   \n",
    "    [128, 0, 128], \n",
    "    [0, 128, 128], \n",
    "    [0, 0, 128],   \n",
    "    [139, 69, 19],  # 갈색. 사람\n",
    "    [255, 165, 0],\n",
    "    [255, 192, 203],\n",
    "    [255, 255, 255], \n",
    "    [255, 105, 180], \n",
    "    [240, 230, 140]  \n",
    "    ]   \n",
    "    rt = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            rt[i, j] = colors[img[i, j]]\n",
    "    return torch.from_numpy(rt).permute(2,0,1)\n",
    "# Aeroplane\t1\n",
    "# Bicycle\t2\n",
    "# Bird\t3\n",
    "# Boat\t4\n",
    "# Bottle\t5\n",
    "# Bus\t6\n",
    "# Car\t7\n",
    "# Cat\t8\n",
    "# Chair\t9\n",
    "# Cow\t10\n",
    "# Diningtable\t11\n",
    "# Dog\t12\n",
    "# Horse\t13\n",
    "# Motorbike\t14\n",
    "# Person\t15\n",
    "# Pottedplant\t16\n",
    "# Sheep\t17\n",
    "# Sofa\t18\n",
    "# Train\t19\n",
    "# Tvmonitor\t20\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wut\n",
      "training runing_loss :  1.4229253199908252\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.302691550372721\n",
      "Saving Best Model\n",
      "training runing_loss :  1.2662628484391123\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.2586691548208615\n",
      "Saving Best Model\n",
      "training runing_loss :  1.2291069103231846\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.2445706871266549\n",
      "Saving Best Model\n",
      "training runing_loss :  1.2052148907888132\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.2177973633202224\n",
      "Saving Best Model\n",
      "training runing_loss :  1.1895797132957178\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1907126194910034\n",
      "Saving Best Model\n",
      "training runing_loss :  1.1782605827180415\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1866759636163056\n",
      "Saving Best Model\n",
      "training runing_loss :  1.1695988497447447\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1832208016907775\n",
      "Saving Best Model\n",
      "training runing_loss :  1.1594684846251389\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.18375022316372\n",
      "training runing_loss :  1.1519179070582155\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.183448720641516\n",
      "training runing_loss :  1.142019900467878\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1638377300248697\n",
      "Saving Best Model\n",
      "training runing_loss :  1.132008024577886\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.155228473000474\n",
      "Saving Best Model\n",
      "training runing_loss :  1.1218079782085992\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1440341722342995\n",
      "Saving Best Model\n",
      "training runing_loss :  1.1110272004467543\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1576687103280654\n",
      "training runing_loss :  1.102420302443817\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1467838391334146\n",
      "training runing_loss :  1.0940329896622016\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1431592644325324\n",
      "Saving Best Model\n",
      "training runing_loss :  1.0844119447665137\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1228250966376656\n",
      "Saving Best Model\n",
      "training runing_loss :  1.074584872426231\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1195275982493882\n",
      "Saving Best Model\n",
      "training runing_loss :  1.0662941178663181\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1225003473215052\n",
      "training runing_loss :  1.0554727808536728\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1271147740247485\n",
      "training runing_loss :  1.0436433021976648\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1104892007187828\n",
      "Saving Best Model\n",
      "training runing_loss :  1.032672591385294\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1206829388636155\n",
      "training runing_loss :  1.0207324398508488\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.116808656439349\n",
      "training runing_loss :  1.0075211876728496\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1291965920437168\n",
      "training runing_loss :  0.9966836222371117\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.115385392250923\n",
      "training runing_loss :  0.9834526358732109\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1060217862518935\n",
      "Saving Best Model\n",
      "training runing_loss :  0.9717808353607772\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.0955195944797207\n",
      "Saving Best Model\n",
      "training runing_loss :  0.9609377869491369\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.0878436765991724\n",
      "Saving Best Model\n",
      "training runing_loss :  0.9493470510335568\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.081362952447527\n",
      "Saving Best Model\n",
      "training runing_loss :  0.9325895107509009\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.0951145457533689\n",
      "training runing_loss :  0.9200598854021947\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.0971948899287771\n",
      "training runing_loss :  0.9083307693239118\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.090812539088202\n",
      "training runing_loss :  0.8871696036044365\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1247716301663235\n",
      "training runing_loss :  0.8698906955497513\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.110395674276483\n",
      "training runing_loss :  0.8657564121843035\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1254244734133994\n",
      "training runing_loss :  0.8377394592338573\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1736732094579345\n",
      "training runing_loss :  0.8259555424253145\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1455234931065486\n",
      "training runing_loss :  0.8238634771662332\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.0881511506593817\n",
      "training runing_loss :  0.8059863050778707\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.2074029888589304\n",
      "training runing_loss :  0.784520042235734\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.093103803489562\n",
      "training runing_loss :  0.7650438882206958\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1648633867952523\n",
      "training runing_loss :  0.7441673132646931\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.1279639872507408\n",
      "training runing_loss :  0.7181163415557048\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.103784283357007\n",
      "training runing_loss :  0.7010633816403118\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.0797601144474287\n",
      "Saving Best Model\n",
      "training runing_loss :  0.680138961579956\n",
      "Finised Training... Start Validation.\n",
      "validation_loss : 1.0670431826550226\n",
      "Saving Best Model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     46\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 48\u001b[0m     train_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining runing_loss : \u001b[39m\u001b[38;5;124m'\u001b[39m,train_loss\u001b[38;5;241m/\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     51\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,train_loss\u001b[38;5;241m/\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m),epoch)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('wut')\n",
    "best_val_loss = 50\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    train_loss = 0.0\n",
    "    validation_loss =0.0\n",
    "    validation_dice =0.0\n",
    "    epoch_dice_scroe = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for i ,data in enumerate(train_loader):\n",
    "        \n",
    "        inputs,labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        inputs.requires_grad_(True)\n",
    "        labels=labels.squeeze(1)\n",
    "        labels = (labels).to(device)\n",
    " \n",
    "\n",
    "        outputs = model(inputs)\n",
    "        outputs_softmax = outputs.softmax(dim=1)\n",
    "\n",
    "        celossval=celoss(outputs,labels)\n",
    "\n",
    "\n",
    "   \n",
    "        labels_no_255 = torch.where(labels >= 255, torch.zeros_like(labels), labels)\n",
    "\n",
    "        loss = celossval\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+= loss.item()\n",
    "        \n",
    "    print('training runing_loss : ',train_loss/(i+1))\n",
    "    writer.add_scalar('train_loss',train_loss/(i+1),epoch)\n",
    "    print('Finised Training... Start Validation.')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(val_loader):\n",
    "            inputs,labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.squeeze(1)\n",
    "            labels = (labels).to(device)\n",
    "            labels.requires_grad_(False)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "           \n",
    "            \n",
    "            celossval=celoss(outputs,labels)\n",
    "            \n",
    "            outputs_softmax = outputs.softmax(dim=1)\n",
    "           \n",
    "            labels_no_255 = torch.where(labels >= 255, torch.zeros_like(labels), labels)\n",
    "            \n",
    "            loss = celossval\n",
    "            \n",
    "            validation_loss+= loss.item()\n",
    "        print(\"validation_loss :\", validation_loss/(i) )\n",
    "        writer.add_scalar('validataion loss : ',validation_loss/(i),epoch)\n",
    "        pred_idx_map = torch.argmax(outputs_softmax,dim=1)\n",
    "        output_with_color = make_sementic_image(pred_idx_map[0])\n",
    "        writer.add_image('model_output',output_with_color,epoch)\n",
    "        writer.add_image('original_image',(inputs[0]*0.5+0.5),epoch)\n",
    "        \n",
    "        if best_val_loss > validation_loss/i:\n",
    "            best_val_loss = validation_loss/i\n",
    "            print(\"Saving Best Model\")\n",
    "            model_copy = copy.deepcopy(model).cpu()\n",
    "            torch.save(model_copy,'./UNet.pth')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
